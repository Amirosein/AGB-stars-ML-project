{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGB_Project_3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rtrBj0jSXW18",
        "ehfv0tjRWfi5",
        "rndMAvy3dH7v",
        "CgPKOiWvn3i2",
        "sVbcG7sDUPxo",
        "3M-w7EtWXDyC",
        "7NTv0PKdmQvq",
        "J7akJtGMVE76",
        "-T1naw4X43YP"
      ],
      "authorship_tag": "ABX9TyPYAg2K/M8AH8tdSNBbmHCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Churchiill/AGB-stars-ML-project/blob/main/Milestone3/AGB_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtrBj0jSXW18"
      },
      "source": [
        "# Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhSAIZ3yhDgo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io, requests\n",
        "import seaborn as sns"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIMBeMlahMQt"
      },
      "source": [
        "username = 'Churchiill'\n",
        "token = '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'\n",
        "\n",
        "github_session = requests.Session()\n",
        "github_session.auth = (username, token)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iIxbs3rSKvh"
      },
      "source": [
        "# 3<sup>rd</sup> Milestone "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehfv0tjRWfi5"
      },
      "source": [
        "# load previous milestone data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYacOj4RSglE"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/Churchiill/AGB-stars-ML-project/main/Milestone1/data/All%20data?token=ATDLLFCO6G7TRES2RLHTUBDASJCUU'\n",
        "dcsv = github_session.get(url).content\n",
        "data = pd.read_csv(io.BytesIO(dcsv), index_col=0, header=0 )\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Churchiill/AGB-stars-ML-project/main/Milestone1/data/X.csv?token=ATDLLFCMJWUMWZHMF2KCEYTASJANQ\"\n",
        "Xcsv = github_session.get(url).content\n",
        "X = pd.read_csv(io.BytesIO(Xcsv), index_col=0, header=0 )\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Churchiill/AGB-stars-ML-project/main/Milestone1/data/Y.csv?token=ATDLLFHYGATBJ63OACMFSDTASJDDQ'\n",
        "Ycsv = github_session.get(url).content\n",
        "Y = pd.read_csv(io.BytesIO(Ycsv), index_col=0, header=0 )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KVPqxcI4xcK"
      },
      "source": [
        "---\n",
        "\n",
        "> * **Ordinal Encoding (for SVC, LDA,...)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4wIl5jV4wXm",
        "outputId": "540218e6-0fce-48bb-db35-25bdc504cf8f"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Label encoding\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data['class'])\n",
        "Ordinal_Y = le.transform(data['class']) \n",
        "Y_O = pd.DataFrame(Ordinal_Y)\n",
        "Y_O.columns = ['Y']\n",
        "\n",
        "le.inverse_transform([0, 1, 2, 3, 4])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['C_AGB', 'O_AGB', 'S_AGB', 'YSO', 'post_AGB'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rndMAvy3dH7v"
      },
      "source": [
        "# Scaling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsXtxkyDdMia"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "\n",
        "r_scaler = RobustScaler()\n",
        "X_robust = r_scaler.fit_transform(X)\n",
        "X_robust = pd.DataFrame(X_robust, columns= X.columns)\n",
        "\n",
        "s_scaler = StandardScaler()\n",
        "X_standard = s_scaler.fit_transform(X)\n",
        "X_standard = pd.DataFrame(X_standard, columns= X.columns)\n",
        "\n",
        "mm_scaler = MinMaxScaler()\n",
        "X_minmax = mm_scaler.fit_transform(X)\n",
        "X_minmax = pd.DataFrame(X_minmax, columns= X.columns)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgPKOiWvn3i2"
      },
      "source": [
        "# PCA data reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q6Jg9tEn_Za"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA on X\n",
        "t = X\n",
        "pca = PCA()\n",
        "t = pca.fit_transform(t)\n",
        "X_p = pd.DataFrame(t)   \n",
        "\n",
        "\n",
        "# PCA on Robust scaled X\n",
        "t = X_robust\n",
        "rpca = PCA()\n",
        "t = rpca.fit_transform(t)\n",
        "X_pr = pd.DataFrame(t) \n",
        "\n",
        "\n",
        "# PCA on MinMax. scaled X\n",
        "t = X_minmax\n",
        "mpca = PCA()\n",
        "t = mpca.fit_transform(t)\n",
        "X_pm = pd.DataFrame(t)   \n",
        "\n",
        "\n",
        "# PCA on Standard scaled X\n",
        "t = X_standard\n",
        "spca = PCA()\n",
        "t = spca.fit_transform(t)\n",
        "X_ps = pd.DataFrame(t)   "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVbcG7sDUPxo"
      },
      "source": [
        "# Validation curve function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy5R4PI3VEiP"
      },
      "source": [
        "from sklearn.model_selection import learning_curve, validation_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def plot_validation_curve(estimator, X, Y, param_range, param_name, \n",
        "                          cv=None, Modelname='', n_jobs=None, xlog=False):\n",
        "  \n",
        "\n",
        "  clf = estimator\n",
        "\n",
        "  train_scores, test_scores = validation_curve(\n",
        "      clf, X, Y, cv=cv, n_jobs=n_jobs, \n",
        "      param_name=param_name, param_range=param_range)\n",
        "  \n",
        "  train_scores_mean = np.mean(train_scores, axis=1)\n",
        "  train_scores_std = np.std(train_scores, axis=1)\n",
        "  test_scores_mean = np.mean(test_scores, axis=1)\n",
        "  test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.title(f\"Validation Curve with {Modelname}\")\n",
        "  plt.xlabel(f\"{param_name}\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.ylim(0.0, 1.1)\n",
        "  lw = 2\n",
        "  \n",
        "  if (xlog):\n",
        "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
        "             color=\"darkorange\", lw=lw)\n",
        "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "             color=\"navy\", lw=lw)\n",
        "  else:\n",
        "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
        "             color=\"darkorange\", lw=lw)\n",
        "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "             color=\"navy\", lw=lw)\n",
        "\n",
        "\n",
        "\n",
        "  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                 color=\"darkorange\", lw=lw)\n",
        "  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
        "                 color=\"navy\", lw=lw)\n",
        "  plt.legend(loc=\"best\")\n",
        "  return plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfQFWBMGnWmv"
      },
      "source": [
        "from sklearn.model_selection import learning_curve, validation_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def plot_validation_curve_KNN(estimator, X, Y, param_range, param_name, \n",
        "                          cv=None, Modelname='', n_jobs=None, xlog=False):\n",
        "  \n",
        "\n",
        "  clf = estimator\n",
        "\n",
        "  train_scores, test_scores = validation_curve(\n",
        "      clf, X, Y, cv=cv, n_jobs=n_jobs, \n",
        "      param_name=param_name, param_range=param_range,scoring = 'neg_mean_squared_error')\n",
        "  \n",
        "  train_scores_mean = np.mean(train_scores, axis=1)\n",
        "  train_scores_std = np.std(train_scores, axis=1)\n",
        "  test_scores_mean = np.mean(test_scores, axis=1)\n",
        "  test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.title(f\"Validation Curve with {Modelname}\")\n",
        "  plt.xlabel(f\"{param_name}\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.ylim(0.0, 1.1)\n",
        "  lw = 2\n",
        "  \n",
        "  if (xlog):\n",
        "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
        "             color=\"darkorange\", lw=lw)\n",
        "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "             color=\"navy\", lw=lw)\n",
        "  else:\n",
        "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
        "             color=\"darkorange\", lw=lw)\n",
        "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "             color=\"navy\", lw=lw)\n",
        "\n",
        "\n",
        "\n",
        "  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                 color=\"darkorange\", lw=lw)\n",
        "  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
        "                 color=\"navy\", lw=lw)\n",
        "  plt.legend(loc=\"best\")\n",
        "  return plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M-w7EtWXDyC"
      },
      "source": [
        "# Grid Search function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsjbGQHXXElJ"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def grid_search(estimator, X, Y, parameters):\n",
        "\n",
        "  clf = GridSearchCV(estimator, parameters)\n",
        "  clf.fit(X, Y)\n",
        "\n",
        "  print(f'The best parameters of the clf are: \\n {clf.best_params_} \\n')\n",
        "\n",
        "  return clf\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZvUJt8hdYSb"
      },
      "source": [
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "def grid_search_KNN(estimator, X, Y, parameters):\n",
        "\n",
        "  clf = GridSearchCV(estimator, parameters, scoring='f1_weighted' )\n",
        "  clf.fit(X, Y)\n",
        "\n",
        "  print(f'The best parameters of the clf are: \\n {clf.best_params_} \\n')\n",
        "\n",
        "  return clf"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NTv0PKdmQvq"
      },
      "source": [
        "# Learning curve function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwZGJ1JDmSAk"
      },
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(0.1, 1, 10)):\n",
        "    \n",
        "\n",
        "    plt.figure(figsize=(10, 6), dpi=80)\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7akJtGMVE76"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfGw-c6HUXRM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "30bfcb3d-7e04-472b-eb87-553e491b0d89"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, recall_score, precision_score, f1_score, classification_report, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def Model_eval(estimator, x_test, y_test, Modelname='', normalize='true'):\n",
        "\n",
        "    clf = estimator\n",
        "    \n",
        "    #ts = test_size\n",
        "    #x_train, x_test, y_train, y_test=train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "\n",
        "    #clf.fit(x_train , y_train)\n",
        "\n",
        "\n",
        "    print(f\"The accuracy of the {Modelname} CLF is \\n {clf.score(x_test, y_test )}.\\n\")\n",
        "    print(f\"The recall of the {Modelname} CLF is  \\n {recall_score(y_test, clf.predict(x_test), average = 'macro')}.\\n\"  )\n",
        "    print(f\"The precision of the {Modelname} CLF is  \\n {precision_score(y_test, clf.predict(x_test), average='macro' , zero_division=0)}.\\n\"  )\n",
        "    print(f\"The f score of the {Modelname} CLF is  \\n {f1_score(y_test, clf.predict(x_test), average='macro')}.\\n\"  )\n",
        "    \n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    plot_confusion_matrix(clf, x_test, y_test,  ax=ax, normalize=normalize)\n",
        "\n",
        "    clf_report = classification_report(y_test, clf.predict(x_test),zero_division=0)\n",
        "    print(clf_report)\n",
        "\n",
        "    return\n",
        "\n",
        "'''\n",
        "    y_predicted = clf.decision_function(x_test).T\n",
        "    plt_title = f'Precision-Recall Curve \\n {Modelname} with a rbf kernel\\n'\n",
        "    x_label = 'Recall'\n",
        "    y_label = 'Precision'\n",
        "\n",
        "    fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "    for pos_label in [0,1,2,3,4]:\n",
        "        precision, recall, thresholds = precision_recall_curve(y_test, y_predicted[pos_label], pos_label=pos_label )\n",
        "        ax = fig.add_subplot(2,3,pos_label+1,xlabel=x_label, ylabel = y_label, title = plt_title+'for class : {}'.format([pos_label])   )\n",
        "        plt.plot(recall, precision)\n",
        "        plt.grid() \n",
        "        \n",
        "        plt.tight_layout() \n",
        "'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n    y_predicted = clf.decision_function(x_test).T\\n    plt_title = f'Precision-Recall Curve \\n {Modelname} with a rbf kernel\\n'\\n    x_label = 'Recall'\\n    y_label = 'Precision'\\n\\n    fig = plt.figure(figsize=(15,10))\\n\\n    for pos_label in [0,1,2,3,4]:\\n        precision, recall, thresholds = precision_recall_curve(y_test, y_predicted[pos_label], pos_label=pos_label )\\n        ax = fig.add_subplot(2,3,pos_label+1,xlabel=x_label, ylabel = y_label, title = plt_title+'for class : {}'.format([pos_label])   )\\n        plt.plot(recall, precision)\\n        plt.grid() \\n        \\n        plt.tight_layout() \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3Xgls8FFcqC"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, recall_score, precision_score, f1_score, classification_report, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def Model_eval_1(estimator, x_test, y_test, Modelname='', normalize='true'):\n",
        "\n",
        "    clf = estimator\n",
        "    \n",
        "    #ts = test_size\n",
        "    #x_train, x_test, y_train, y_test=train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "\n",
        "    #clf.fit(x_train , y_train)\n",
        "\n",
        "\n",
        "    print(f\"The accuracy of the {Modelname} CLF is \\n {clf.score(x_test, y_test )}.\\n\")\n",
        "    print(f\"The recall of the {Modelname} CLF is  \\n {recall_score(y_test, clf.predict(x_test), average = 'macro')}.\\n\"  )\n",
        "    print(f\"The precision of the {Modelname} CLF is  \\n {precision_score(y_test, clf.predict(x_test), average='macro' , zero_division=0)}.\\n\"  )\n",
        "    print(f\"The f score of the {Modelname} CLF is  \\n {f1_score(y_test, clf.predict(x_test), average='macro')}.\\n\"  )\n",
        "    \n",
        "\n",
        "    \n",
        "    plot_confusion_matrix(clf, x_test, y_test, normalize=normalize)\n",
        "\n",
        "    clf_report = classification_report(y_test, clf.predict(x_test),zero_division=0)\n",
        "    print(clf_report)\n",
        "\n",
        "    return\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKjWztR-OFgo"
      },
      "source": [
        "---\n",
        "\n",
        "> # **Fitting Models:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T1naw4X43YP"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBvsB229414D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}